{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# a = timm.create_model('densenet121', in_chans=3, num_classes=0, pretrained=False)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa46423-4220-438d-b804-f70c32b6db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96949c-3a6b-4be1-bb10-3212a6e8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.data import create_transform\n",
    "from torchvision.transforms import v2\n",
    "import PIL\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "size=512\n",
    "\n",
    "ratio = 1.0\n",
    "transform_train = v2.Compose([\n",
    "                      v2.RandomResizedCrop(size=(size, size), scale= (0.87, 1.0), ratio=(0.7, 1.3), interpolation=v2.InterpolationMode.BICUBIC ), #  ratio=(0.7, 1.3),\n",
    "                    v2.RandomHorizontalFlip(p=0.5),\n",
    "                    v2.RandomVerticalFlip(p=0.5),\n",
    "                    v2.RandomApply([v2.RandomRotation(180)]),\n",
    "                    v2.RandomApply([v2.ColorJitter(0.2,0.2,0.2,0.1)], 0.2), # brightness, contrast, saturation, hue\n",
    "                    v2.RandomGrayscale(p=0.25),\n",
    "                    v2.RandomApply([v2.GaussianBlur(kernel_size=7, sigma=0.5)],0.2),\n",
    "                    v2.ToTensor(),\n",
    "                    \n",
    "        ]) \n",
    "transform_val = v2.Compose([\n",
    "                    v2.Resize(int(1.1*size), interpolation=PIL.Image.BICUBIC),\n",
    "                    v2.CenterCrop(size),\n",
    "                    v2.ToTensor(),\n",
    "        ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd4a52-9f05-417f-9a73-9499e2612ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageModel(models):\n",
    "    model_avg = models[0]  # Start with the first model's architecture\n",
    "\n",
    "# Sum the weights of each model\n",
    "    with torch.no_grad():\n",
    "        for param_tensor in model_avg.state_dict():\n",
    "            avg_param = torch.zeros_like(model_avg.state_dict()[param_tensor])\n",
    "            for model in models:\n",
    "                avg_param += model.state_dict()[param_tensor]\n",
    "            avg_param /= len(models)\n",
    "            model_avg.state_dict()[param_tensor].copy_(avg_param)\n",
    "    return model_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded6bbd-a0a7-4ac7-8290-999a5534c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    return dir\n",
    "import cv2\n",
    "def Clahe(image):\n",
    "    gray_array0 = np.asarray(image)\n",
    "    gray_array0 = cv2.cvtColor(gray_array0, cv2.COLOR_RGB2GRAY)\n",
    "    gray_array = gray_array0.astype(np.uint8)\n",
    "\n",
    "# Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Apply CLAHE to the grayscale image\n",
    "    clahe_image = clahe.apply(gray_array)\n",
    "\n",
    "# Convert the NumPy array back to PIL image\n",
    "    clahe_pil_image = Image.fromarray(clahe_image)\n",
    "    return clahe_pil_image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, vessel,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root))  # list of class names\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}  # mapping from class name to index\n",
    "        self.images = []  # list of tuples (image_path, class_index)\n",
    "        self.normalize_color = v2.Normalize(mean, std)\n",
    "        # self.normalize_binary = v2.Normalize((0.5,), (0.5,))\n",
    "        self.n_classes = 5\n",
    "        # self.additional_aug = v2.RandomChoice([\n",
    "        #             v2.RandomHorizontalFlip(p=1),\n",
    "        #             v2.RandomVerticalFlip(p=1),\n",
    "        #             v2.RandomApply([v2.ColorJitter(0.1,0.1,0.1,0.1)], p=1), # brightness, contrast, saturation, hue\n",
    "                    \n",
    "        # ]) \n",
    "\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root, class_name)\n",
    "            vessel_dir = os.path.join(vessel, class_name)\n",
    "            for image_name in sorted(os.listdir(class_dir)):\n",
    "\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                vessel_path = os.path.join(vessel_dir, image_name)\n",
    "                self.images.append((image_path, self.class_to_idx[class_name], vessel_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    # def add_gaussian_noise(self, tensor, mean=0.0, std=1.0):\n",
    "    #     noise = torch.randn(tensor.shape) * std + mean\n",
    "    #     noisy_tensor = tensor + noise\n",
    "    #     return noisy_tensor\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path, class_index, vessel_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = self.transform(image)\n",
    "        image  = self.normalize_color(image)\n",
    "        # vessel = self.transform(vessel)\n",
    "        # vessel = self.normalize_binary(vessel)\n",
    "\n",
    "        # image2 = self.add_gaussian_noise(image1_)\n",
    "\n",
    "        # image2 = self.normalize_color(image2)\n",
    "\n",
    "        return {\"image\":image, \"label\":class_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "img_type = 'DDR'\n",
    "path = img_type + '_dataset/'\n",
    "img_dir = '/home/monetai2/Desktop/LabFolder/Pham/datasets/DDR/preprocessed/'\n",
    "train_data = CustomDataset(root=img_dir+'train/', vessel=img_dir+'train/', transform=transform_train)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_data))\n",
    "print(train_data.class_to_idx)\n",
    "\n",
    "val_data = CustomDataset(root=img_dir+'val/', vessel=img_dir+'val/', transform=transform_val)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "print(len(val_data))\n",
    "print(val_data.class_to_idx)\n",
    "\n",
    "checkpoint_path = 'checkpoint/'\n",
    "check_folder(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d23415",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(trainloader)\n",
    "data = next(data_iter)\n",
    "\n",
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(data[\"vessel\"]))\n",
    "# print labels\n",
    "print( data[\"label\"][j] for j in range(batch_size))\n",
    "imshow(torchvision.utils.make_grid(data[\"image\"]))\n",
    "print(data[\"label\"][j] for j in range(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63190699",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd499350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        \n",
    "        # Squeeze operation: Global average pooling (AdaptiveAvgPool2d outputs a single value per channel)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Excitation operation: Two fully connected (FC) layers\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction_ratio, bias=False)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction_ratio, in_channels, bias=False)\n",
    "        \n",
    "        # Activation layers: ReLU followed by Sigmoid\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # Squeeze: Global Average Pooling (reshape output to [batch_size, channels])\n",
    "        squeeze = self.global_avg_pool(x).view(batch_size, channels)\n",
    "        \n",
    "        # Excitation: FC -> ReLU -> FC -> Sigmoid\n",
    "        excitation = self.fc1(squeeze)\n",
    "        excitation = self.relu(excitation)\n",
    "        excitation = self.fc2(excitation)\n",
    "        excitation = self.sigmoid(excitation)\n",
    "\n",
    "        # Reshape the excitation weights back to [batch_size, channels, 1, 1]\n",
    "        excitation = excitation.view(batch_size, channels, 1, 1)\n",
    "        \n",
    "        # Scale the input feature maps by the excitation weights (channel-wise multiplication)\n",
    "        x = x * excitation\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ChannelAttention4x(nn.Module):\n",
    "    def __init__(self, channels, expand=4):\n",
    "        super(ChannelAttention4x, self).__init__()\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels * expand , 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels * expand, channels * expand , 1, groups=channels * expand, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels * expand, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        y = x*y\n",
    "        return y\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)*x\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)*x\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_chans):\n",
    "        super(CBAM, self).__init__()\n",
    "\n",
    "        self.ca = ChannelAttention(in_chans)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ca(x)\n",
    "        x = self.sa(x)\n",
    "        return x        \n",
    "class MKB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MKB, self).__init__()\n",
    "        \n",
    "        # Ensure the dilations tuple is the correct length (three branches)\n",
    "\n",
    "        # First branch with dilation 1\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU(),\n",
    "                                   SqueezeExcitation(out_channels)                                   \n",
    "                                  )\n",
    "        # Second branch with dilation 2\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=5, padding='same'),                                   \n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU(),\n",
    "                                   SqueezeExcitation(out_channels)\n",
    "                                  )\n",
    "        \n",
    "        # Third branch with dilation 3\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=7, padding='same'),                                   \n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU(),\n",
    "                                   SqueezeExcitation(out_channels)\n",
    "                                  )\n",
    "\n",
    "        self.conv1x1_1 = nn.Conv2d(out_channels*3,out_channels, kernel_size=1, bias=False)\n",
    "                             \n",
    "                                      \n",
    "        # self.relu1 = nn.ReLU()\n",
    "        self.conv1x1_2 = nn.Conv2d(out_channels,out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute the outputs of each parallel branch\n",
    "        out1 = self.conv1(x)\n",
    "        out1 = out1 + x\n",
    "        \n",
    "        out2 = self.conv2(x)\n",
    "        out2 = out2 + x\n",
    "        \n",
    "        out3 = self.conv3(x)\n",
    "        out3 = out3 + x\n",
    "\n",
    "\n",
    "        # Sum the outputs from the parallel branches\n",
    "        out = torch.cat((out1,out2,out3),dim=1)\n",
    "        \n",
    "        out = self.conv1x1_1(out)\n",
    "        out = self.conv1x1_2(out)\n",
    "        out = x + out\n",
    "        return out\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.net1 = timm.create_model('coatnet_rmlp_2_rw_224', img_size=size, in_chans=3,  num_classes=5,  pretrained=True)\n",
    "        self.ca_stem = MKB(128,128)\n",
    "        self.ca_stage0 = MKB(128,128)\n",
    "        self.ca_stage1 = MKB(256,256)\n",
    "\n",
    "\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.net1.stem(x)\n",
    "        x = self.ca_stem(x)\n",
    "\n",
    "        n = len(self.net1.stages)\n",
    "\n",
    "        for i in range(n):\n",
    "            x = self.net1.stages[i](x)\n",
    "            if i == 0:\n",
    " \n",
    "                x = self.ca_stage0(x)\n",
    "            elif i == 1:\n",
    "\n",
    "                x = self.ca_stage1(x)               \n",
    "        x = self.net1.norm(x)\n",
    "        return x\n",
    "                \n",
    "    def forward(self, x, std=0.0):\n",
    "\n",
    "        ft = self.forward_features(x)\n",
    "\n",
    "\n",
    "        y = self.net1.forward_head(ft)\n",
    "\n",
    "        return y , ft      \n",
    "network = 'proposed'\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "net = CustomModel()\n",
    "# net.load_state_dict(torch.load(\"checkpoint/DDR_seed0_proposed512_kappa_ema.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ad246-84ca-4e83-8a9c-dfeec57fe3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f50bbe-bd68-452c-8551-f2b930ca8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEmaV2(nn.Module):\n",
    "    def __init__(self, model, decay=0.9998, device=None):\n",
    "        super(ModelEmaV2, self).__init__()\n",
    "        # make a copy of the model for accumulating moving average of weights\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device  # perform ema on different device from model if set\n",
    "        if self.device is not None:\n",
    "            self.module.to(device=device)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(), model.state_dict().values()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "\n",
    "    def update(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "    def update_decay(self, new_decay):\n",
    "        self.decay = new_decay\n",
    "    def set(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: m)\n",
    "model_ema = ModelEmaV2(net, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90152bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30\n",
    "global trn_loss \n",
    "global tst_loss \n",
    "global trn_acc\n",
    "global tst_acc\n",
    "\n",
    "trn_loss = torch.zeros(epochs)\n",
    "tst_loss= torch.zeros(epochs)\n",
    "trn_acc = torch.zeros(epochs)\n",
    "tst_acc = torch.zeros(epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch, coeff=0, coeff_ema=0.9996):\n",
    "    # model_ema.update_decay(coeff_ema)\n",
    "    # print('ema weight' , coeff_ema)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for batch_idx, data in enumerate(trainloader):\n",
    "\n",
    "            images = data[\"image\"].to(device)\n",
    "            labels = data[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, f1 = net(images, std)\n",
    "            _, predicted = outputs.max(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if model_ema is not None:\n",
    "                model_ema.update(net)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fa34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    net.eval()\n",
    "    # net_ema.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    ground_truth = []\n",
    "    pred_ema = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(valloader):\n",
    "\n",
    "\n",
    "            images = data[\"image\"].to(device)\n",
    "            labels = data[\"label\"].to(device)\n",
    "            # labels = labels.max(dim=1)[0]\n",
    "            # grays = transforms.Grayscale()(images).to(device)\n",
    "\n",
    "            outputs,_ = net(images, std=1.)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # _, labels = labels.max(1)\n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(valloader), 'Val Loss: %.3f | Val Acc: %.3f%% (%d/%d)' % (val_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            \n",
    "            pred.extend(predicted.data.cpu().numpy().tolist())\n",
    "            ground_truth.extend(labels.data.cpu().numpy().flatten().tolist())\n",
    "            \n",
    "            net_ema = model_ema.module            \n",
    "            outputs_ema,_ = net_ema(images, std=1.)\n",
    "            _, predicted_ema = outputs_ema.max(1)\n",
    "            pred_ema.extend(predicted_ema.data.cpu().numpy().tolist())\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    return val_loss, np.asarray(pred), np.asarray(ground_truth), acc, np.asarray(pred_ema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78476df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import functional as F\n",
    "# class FocalLoss(torch.nn.Module):\n",
    "#     def __init__(self, alpha, gamma=2.0):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha  # Precomputed alpha values\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         log_probs = F.log_softmax(inputs, dim=1)  # Log-probabilities\n",
    "#         probs = torch.exp(log_probs)             # Probabilities\n",
    "#         log_p = log_probs[range(len(targets)), targets]\n",
    "#         p = probs[range(len(targets)), targets]\n",
    "\n",
    "#         focal_term = (1 - p) ** self.gamma\n",
    "#         loss = -focal_term * log_p\n",
    "\n",
    "#         # Apply alpha values\n",
    "#         alpha_t = self.alpha[targets]  # Select alpha for true classes\n",
    "#         loss = alpha_t * loss\n",
    "\n",
    "#         return loss.mean()\n",
    "\n",
    "# class_counts = np.array([3133, 315, 2238, 118, 456])  # Class 0: 100 samples, Class 1: 300 samples\n",
    "# total_samples = sum(class_counts)\n",
    "# class_weights = total_samples / class_counts\n",
    "# print(\"Class Weights:\", class_weights)\n",
    "# class_weights = class_weights / class_weights.sum()\n",
    "# print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# # Convert to a PyTorch tensor\n",
    "# class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)\n",
    "criterion_mse = nn.MSELoss()\n",
    "lr = 1e-5\n",
    "optimizer = optim.AdamW(net.parameters(), lr=lr, weight_decay = 0.01)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "# scheduler = StepLRScheduler(optimizer, decay_t=10, decay_rate=0.8)\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "# scheduler1 = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "#                                                    max_lr=lr, \n",
    "#                                                    total_steps=epochs*len(trainloader))\n",
    "# scheduler = PlateauLRScheduler(optimizer, decay_rate=0.2, patience_t=3, warmup_t=3, warmup_lr_init=1e-7)\n",
    "# scheduler = CosineLRScheduler(optimizer, t_initial=epochs, warmup_t=3, warmup_lr_init=1e-7)\n",
    "best_acc = 0  # best test accuracy\n",
    "# base_opt = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# opt = torchcontrib.optim.SWA(base_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba2da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, recall_score, precision_score, f1_score, cohen_kappa_score, accuracy_score, auc, classification_report, confusion_matrix\n",
    "from imblearn.metrics import sensitivity_score, specificity_score\n",
    "# def quadratic_weighted_kappa(conf_mat):\n",
    "#     assert conf_mat.shape[0] == conf_mat.shape[1]\n",
    "#     cate_num = conf_mat.shape[0]\n",
    "\n",
    "#     # Quadratic weighted matrix\n",
    "#     weighted_matrix = np.zeros((cate_num, cate_num))\n",
    "#     for i in range(cate_num):\n",
    "#         for j in range(cate_num):\n",
    "#             weighted_matrix[i][j] = 1 - float(((i - j)**2) / ((cate_num - 1)**2))\n",
    "\n",
    "#     # Expected matrix\n",
    "#     ground_truth_count = np.sum(conf_mat, axis=1)\n",
    "#     pred_count = np.sum(conf_mat, axis=0)\n",
    "#     expected_matrix = np.outer(ground_truth_count, pred_count)\n",
    "\n",
    "#     # Normalization\n",
    "#     conf_mat = conf_mat / conf_mat.sum()\n",
    "#     expected_matrix = expected_matrix / expected_matrix.sum()\n",
    "\n",
    "#     observed = (conf_mat * weighted_matrix).sum()\n",
    "#     expected = (expected_matrix * weighted_matrix).sum()\n",
    "#     return (observed - expected) / (1 - expected)\n",
    "def quadratic_weighted_kappa(conf_mat):\n",
    "    assert conf_mat.shape[0] == conf_mat.shape[1]\n",
    "    cate_num = conf_mat.shape[0]\n",
    "\n",
    "    # Quadratic weighted matrix\n",
    "    weighted_matrix = np.zeros((cate_num, cate_num))\n",
    "    for i in range(cate_num):\n",
    "        for j in range(cate_num):\n",
    "            weighted_matrix[i][j] = 1 - float(((i - j)**2) / ((cate_num - 1)**2))\n",
    "\n",
    "    # Expected matrix\n",
    "    ground_truth_count = np.sum(conf_mat, axis=1)\n",
    "    pred_count = np.sum(conf_mat, axis=0)\n",
    "    expected_matrix = np.outer(ground_truth_count, pred_count)\n",
    "\n",
    "    # Normalization\n",
    "    conf_mat = conf_mat / conf_mat.sum()\n",
    "    expected_matrix = expected_matrix / expected_matrix.sum()\n",
    "\n",
    "    observed = (conf_mat * weighted_matrix).sum()\n",
    "    expected = (expected_matrix * weighted_matrix).sum()\n",
    "    return (observed - expected) / (1 - expected)\n",
    "def evaluation_metrics(y_true, y_pred):\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    specificity = specificity_score(y_true, y_pred, average='weighted')\n",
    "    conf = confusion_matrix(y_true, y_pred)\n",
    "    kappa = quadratic_weighted_kappa(conf)\n",
    "\n",
    "    print('micro acc, pre, recall, f1, specificity, kappa: ', accuracy, precision, recall, f1, specificity, kappa)\n",
    "    # for i in range(ground_truth.shape[1]):\n",
    "    #     print('class ',i)\n",
    "    #     print(accuracy_score(ground_truth[:,i], pred[:,i]), precision_score(ground_truth[:,i], pred[:,i]), \n",
    "    #           recall_score(ground_truth[:,i], pred[:,i]), f1_score(ground_truth[:,i], pred[:,i]), specificity_score(ground_truth[:,i], pred[:,i]))\n",
    "        \n",
    "    return accuracy, precision, recall, f1, specificity, kappa\n",
    "best_model = None\n",
    "best_model_ema = None\n",
    "best_kappa = -1.\n",
    "best_kappa_ema = -1.\n",
    "kappa_list = []\n",
    "kappa_list_ema = []\n",
    "\n",
    "best_model_kappa = None\n",
    "best_model_ema_kappa = None\n",
    "best_acc = -1.\n",
    "best_acc_ema = -1.\n",
    "acc_list = []\n",
    "acc_list_ema = []\n",
    "\n",
    "start = time.time()\n",
    "start_epoch = 0  # start from epoch 0 \n",
    "def cosine_scheduler(base_value, final_value, epochs, niter_per_ep, warmup_epochs=0, start_warmup_value=0):\n",
    "    warmup_schedule = np.array([])\n",
    "    warmup_iters = warmup_epochs * niter_per_ep\n",
    "    if warmup_epochs > 0:\n",
    "        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)\n",
    "\n",
    "    # iters = np.arange(epochs * niter_per_ep - warmup_iters)\n",
    "    iters = np.arange(epochs * niter_per_ep - warmup_iters)\n",
    "    schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))\n",
    "\n",
    "    schedule = np.concatenate((warmup_schedule, schedule))\n",
    "    assert len(schedule) == epochs * niter_per_ep\n",
    "    return schedule\n",
    "\n",
    "# no_noise = True\n",
    "# if no_noise == True:\n",
    "#     coff = [0]*epochs\n",
    "# else:\n",
    "#     coff = cosine_scheduler(0.,0.5,epochs,1)\n",
    "def linear_increase(a, b, n):\n",
    "    \"\"\"\n",
    "    Generates a list of values linearly increasing from a to b over n steps.\n",
    "\n",
    "    Parameters:\n",
    "    a (float): The starting value.\n",
    "    b (float): The ending value.\n",
    "    n (int): The number of steps.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of linearly increasing values from a to b.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"Number of steps n must be at least 1\")\n",
    "    \n",
    "    step = (b - a) / (n - 1) if n > 1 else 0\n",
    "    return [a + step * i for i in range(n)]\n",
    "coff_list = linear_increase(0., 0.5, epochs)\n",
    "coff_ema = linear_increase(0.9995,0.9999,epochs)\n",
    "i = 0\n",
    "for epoch in range(start_epoch, start_epoch+epochs):\n",
    "    coff = coff_list[i]\n",
    "\n",
    "    print('epoch ', epoch)\n",
    "    print('coeff:', coff)\n",
    "    print('coeff ema:', coff_ema[i])\n",
    "    train_loss = train(epoch, coeff=coff, coeff_ema=coff_ema[i])\n",
    "    i += 1\n",
    "    val_loss, pred, ground_truth, acc, pred_ema = val(epoch)\n",
    "    print('model')\n",
    "    # print(classification_report(ground_truth, pred, digits=4))\n",
    "    accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred)\n",
    "    kappa_list.append(kappa)\n",
    "    acc_list.append(accuracy)\n",
    "    if kappa > best_kappa:\n",
    "        best_kappa = kappa\n",
    "        best_model_kappa = deepcopy(net)\n",
    "        torch.save(best_model_kappa.state_dict(), checkpoint_path+img_type+'_seed'+str(seed)+'_'+network+str(size)+'_kappa.pth')\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_model = deepcopy(net)\n",
    "        torch.save(best_model.state_dict(), checkpoint_path+img_type+'_seed'+str(seed)+'_'+network+str(size)+'_accuracy.pth')\n",
    "\n",
    "   \n",
    "    print('ema')\n",
    "    accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred_ema)\n",
    "    kappa_list_ema.append(kappa)\n",
    "    acc_list_ema.append(accuracy)\n",
    "    print('kappa: ', kappa)\n",
    "    # kappa = accuracy\n",
    "    if kappa > best_kappa_ema:\n",
    "        best_kappa_ema = kappa\n",
    "        best_model_ema_kappa = deepcopy(model_ema.module)\n",
    "        torch.save(best_model_ema_kappa.state_dict(), checkpoint_path+img_type+'_seed'+str(seed)+'_'+network+str(size)+'_kappa_ema.pth')\n",
    "\n",
    "    if accuracy > best_acc_ema:\n",
    "        best_acc_ema = accuracy\n",
    "        best_model_ema = deepcopy(model_ema.module)\n",
    "        torch.save(best_model_ema.state_dict(), checkpoint_path+img_type+'_seed'+str(seed)+'_'+network+str(size)+'_accuracy_ema.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905068b-9daa-44f3-94dc-b7cb9d17338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ')\n",
    "print('Validation')\n",
    "max_kappa = np.amax(kappa_list)\n",
    "id_kappa = kappa_list.index(max_kappa)\n",
    "print('max kappa {}, at {}'.format(max_kappa,id_kappa))\n",
    "max_kappa_ema = np.amax(kappa_list_ema)\n",
    "id_kappa_ema = kappa_list_ema.index(max_kappa_ema)\n",
    "print('max kappa ema {}, at {}'.format(max_kappa_ema,id_kappa_ema))\n",
    "\n",
    "max_kappa = np.amax(acc_list)\n",
    "id_kappa = acc_list.index(max_kappa)\n",
    "print('max accuracy {}, at {}'.format(max_kappa,id_kappa))\n",
    "max_kappa_ema = np.amax(acc_list_ema)\n",
    "id_kappa_ema = acc_list_ema.index(max_kappa_ema)\n",
    "print('max accuracy ema {}, at {}'.format(max_kappa_ema,id_kappa_ema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda817d-b242-429a-aa8a-ae392b5dcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289ba38-0d20-4c96-8ed2-4f868822fa6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [================>................................................]  Step: 325ms | Tot: 1m18s | Test Loss: 0.758 | Test Acc: 93.568% (902/964)\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "# device = 'cuda'\n",
    "acc= 0\n",
    "# del optimizer\n",
    "print('testing with noise')\n",
    "test_data = CustomDataset(root=img_dir+'test/', vessel=img_dir+'test/', transform=transform_val)\n",
    "testloader = DataLoader(test_data, batch_size=4, shuffle=False)\n",
    "print(len(test_data))\n",
    "print(test_data.class_to_idx)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def test(net, net_ema):\n",
    "    net.eval()\n",
    "    net_ema.eval()\n",
    "    # net = net.to(device)\n",
    "    # net_ema = net_ema.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    ground_truth = []\n",
    "    pred_ema = []\n",
    "    score = []\n",
    "    score_ema = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "\n",
    "            images = data[\"image\"].to(device)\n",
    "            labels = data[\"label\"].to(device)\n",
    "            # lesions = data[\"vessel\"].to(device)\n",
    "\n",
    "            outputs,_ = net(images, std=1.0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # _, labels = labels.max(1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            outputs = torch.softmax(outputs, dim=1)\n",
    "            pred.extend(predicted.data.cpu().numpy().tolist())\n",
    "            score.extend(outputs.data.cpu().numpy().tolist())\n",
    "            ground_truth.extend(labels.data.cpu().numpy().flatten().tolist())\n",
    "            \n",
    "            outputs_ema,_ = net_ema(images, std=1.0)\n",
    "            _, predicted_ema = outputs_ema.max(1)\n",
    "            outputs_ema = torch.softmax(outputs_ema, dim=1)\n",
    "            score_ema.extend(outputs_ema.data.cpu().numpy().tolist())\n",
    "            pred_ema.extend(predicted_ema.data.cpu().numpy().tolist())\n",
    "\n",
    "    return test_loss, np.asarray(pred), np.asarray(ground_truth), acc, np.asarray(pred_ema), np.asarray(score), np.asarray(score_ema)\n",
    "\n",
    "print('best accuracy')\n",
    "net = best_model\n",
    "net_ema = best_model_ema\n",
    "\n",
    "val_loss, pred, ground_truth, acc, pred_ema, score, score_ema = test(net, net_ema)\n",
    "print('model')\n",
    "print(classification_report(ground_truth, pred, digits=4))\n",
    "accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred)\n",
    "print(\"auc \", roc_auc_score(ground_truth, score, average='macro', multi_class='ovr'))\n",
    "print('ema')\n",
    "print(classification_report(ground_truth, pred_ema, digits=4))\n",
    "accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred_ema)\n",
    "print(\"auc \", roc_auc_score(ground_truth, score_ema, average='macro', multi_class='ovr'))\n",
    "\n",
    "print('best kappa')\n",
    "net = best_model_kappa\n",
    "net_ema = best_model_ema_kappa\n",
    "val_loss, pred, ground_truth, acc, pred_ema, score, score_ema = test(net, net_ema)\n",
    "\n",
    "\n",
    "print('model')\n",
    "print(classification_report(ground_truth, pred, digits=4))\n",
    "accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred)\n",
    "print(\"auc \", roc_auc_score(ground_truth, score, average='macro', multi_class='ovr'))\n",
    "print('ema')\n",
    "print(classification_report(ground_truth, pred_ema, digits=4))\n",
    "accuracy, precision, recall, f1, spec, kappa = evaluation_metrics(ground_truth, pred_ema)\n",
    "print(\"auc \", roc_auc_score(ground_truth, score_ema, average='macro', multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1266f-a6f0-4241-8b12-a57ff98c24f3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d16a5",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
